/*
Copyright 2018 VMware, Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

/*
 * This file contains all functions and definitions necessary for the kernel target C code to compile. It must be included with any file generated by the p4c-ebpf kernel compiler.
 * TODO: The exact purpose and correctness of the kernel target is unclear yet.
 * This header file may change substantially.
 */

#ifndef BACKENDS_EBPF_BPFINCLUDE_EBPF_KERNEL_H_
#define BACKENDS_EBPF_BPFINCLUDE_EBPF_KERNEL_H_

// #include <linux/skbuff.h>
// #include <linux/netdevice.h>
// #include <linux/version.h>
#include <linux/bpf.h>
#include <stdbool.h>
#include <stdio.h>
#include "bpf_helpers.h"

/* Additional headers */
# define printk(fmt, ...)                                               \
                ({                                                      \
                        char ____fmt[] = fmt;                           \
                        bpf_trace_printk(____fmt, sizeof(____fmt),      \
                                     ##__VA_ARGS__);                    \
                })


typedef signed char s8;
typedef unsigned char u8;
typedef signed short s16;
typedef unsigned short u16;
typedef signed int s32;
typedef unsigned int u32;
typedef signed long long s64;
typedef unsigned long long u64;


/** helper macro to place programs, maps, license in
 * different sections in elf_bpf file. Section names
 * are interpreted by elf_bpf loader
 */
#define SEC(NAME) __attribute__((section(NAME), used))



unsigned long long load_byte(void *skb,
                             unsigned long long off) asm("llvm.bpf.load.byte");
unsigned long long load_half(void *skb,
                             unsigned long long off) asm("llvm.bpf.load.half");
unsigned long long load_word(void *skb,
                             unsigned long long off) asm("llvm.bpf.load.word");

static inline __attribute__((always_inline))
u64 load_dword(void *skb, u64 off) {
  return ((u64)load_word(skb, off) << 32) | load_word(skb, off + 4);
}

/* simple descriptor which replaces the kernel sk_buff structure */
#define SK_BUFF struct __sk_buff


#define REGISTER_START()
#define REGISTER_TABLE(NAME, TYPE, KEY_SIZE, VALUE_SIZE, MAX_ENTRIES) \
struct bpf_map_def SEC("maps") NAME = {          \
    .type       = TYPE,             \
    .key_size   = KEY_SIZE,         \
    .value_size = VALUE_SIZE,       \
    .max_entries    = MAX_ENTRIES,  \
    .map_flags = 0,                 \
};
#define REGISTER_END()

#define BPF_MAP_LOOKUP_ELEM(table, key) \
    bpf_map_lookup_elem(&table, key)
#define BPF_MAP_UPDATE_ELEM(table, key, value, flags) \
    bpf_map_update_elem(&table, key, value, flags)

#endif  // BACKENDS_EBPF_BPFINCLUDE_EBPF_KERNEL_H_